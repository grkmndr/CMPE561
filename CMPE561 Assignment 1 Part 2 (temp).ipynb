{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[438]:\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "rootDir = '.'\n",
    "TOTAL_TRAINING_DOCUMENT_COUNT = 0\n",
    "DOCUMENT_COUNT_PER_AUTHOR = {}\n",
    "VOCABULARY = set()\n",
    "authorBags = {}\n",
    "authorFeatures = {}\n",
    "\n",
    "def tokenize(text, choice): #if choice is 1 return the bag of words, else return the unique words with their counts\n",
    "    bag = re.split('\\W+', text)\n",
    "    counts = {}\n",
    "    for x in set(bag):\n",
    "        counts.update({x:bag.count(x)})\n",
    "    if choice:\n",
    "        return bag\n",
    "    else:\n",
    "        return counts\n",
    "\n",
    "    \n",
    "def mean_var(counts): #gets a list of feature counts(comma count, word count etc.) of multiple files of one author and returns the mean and the variance of that sample.\n",
    "    mean = sum(counts)/len(counts)\n",
    "    var = 0 #variance\n",
    "    for i in range(0, len(counts)):\n",
    "        var += (counts[i]-mean)**2\n",
    "    var /= len(counts)\n",
    "    return mean,var\n",
    "\n",
    "def gaussian_pdf_value(mean,var,value):\n",
    "    if var==0:\n",
    "        return 1e-40\n",
    "    pdf = (1/np.sqrt(2*np.pi*var)) * np.exp(-1*(((value-mean)**2)/(2*var)))\n",
    "    \n",
    "    if pdf == 0:\n",
    "        return 1e-40\n",
    "    \n",
    "    return pdf \n",
    "\n",
    "def z_score(mean, var, value):\n",
    "    if var==0:\n",
    "        return np.log(1e-40)\n",
    "    return abs(value-mean)/np.sqrt(var)\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(rootDir+'/trainingSet'):\n",
    "    if(dirName != './trainingSet'):\n",
    "        currDir = dirName[14:]\n",
    "        \n",
    "        authorBags.update({currDir:{}})\n",
    "        authorFeatures.update({currDir:{'wordCount':[], #wordCount: total word count for the author.\n",
    "                                        'sentenceCount':[], #sentenceCount: sentence count per document for the author.\n",
    "                                        'wordLength':[], #wordLength: average word length for the author.\n",
    "                                        'commaCount':[], #commaCount: average number of commas per sentence for the author.\n",
    "                                        'exclamationCount':[], #exclamationCount: average number of exclamation marks per sentence for the author.\n",
    "                                        'questionCount':[] #questionCount: average number of question marks per sentence for the author.\n",
    "                                       }}) \n",
    "\n",
    "\n",
    "\n",
    "        #print(authorBags)\n",
    "        fileCount = len(fileList)\n",
    "        ##print(dirName)\n",
    "        DOCUMENT_COUNT_PER_AUTHOR.update({currDir:0})\n",
    "        \n",
    "        for fname in fileList:\n",
    "            TOTAL_TRAINING_DOCUMENT_COUNT += 1\n",
    "            DOCUMENT_COUNT_PER_AUTHOR[currDir] += 1\n",
    "            text = ''\n",
    "            with codecs.open(dirName+'/'+fname, 'r', 'ISO-8859-9') as myfile:\n",
    "                ##print(dirName+'/'+fname)\n",
    "                text = myfile.read().lower()\n",
    "\n",
    "                bagCounts = tokenize(text,0)\n",
    "                wordCount = 0\n",
    "                wordLength = 0\n",
    "                \n",
    "                for word in bagCounts:\n",
    "                    wordCount += bagCounts[word]\n",
    "                    wordLength += bagCounts[word]*len(word)                    \n",
    "                    \n",
    "                    newWord = ''\n",
    "                    if word.isdigit(): newWord = 'NUMBER'\n",
    "                    else: newWord = word\n",
    "                    \n",
    "                    if newWord in authorBags[currDir]:\n",
    "                        authorBags[currDir][newWord] += bagCounts[word]\n",
    "                    else:\n",
    "                        authorBags[currDir].update({newWord:bagCounts[word]})\n",
    "                \n",
    "                sentcount = text.count('.') #sentence count\n",
    "                authorFeatures[currDir]['wordCount'].append(wordCount) #word count of the current file\n",
    "                authorFeatures[currDir]['wordLength'].append(wordLength/wordCount) #average word length for the current file\n",
    "                authorFeatures[currDir]['sentenceCount'].append(sentcount)\n",
    "                authorFeatures[currDir]['commaCount'].append(text.count(',')/sentcount)\n",
    "                authorFeatures[currDir]['exclamationCount'].append(text.count('!')/sentcount)\n",
    "                authorFeatures[currDir]['questionCount'].append(text.count('?')/sentcount)\n",
    "                \n",
    "        if '' in authorBags[currDir]: del authorBags[currDir]['']\n",
    "            \n",
    "        VOCABULARY.update(authorBags[currDir].keys())\n",
    "        \n",
    "        for key in authorFeatures[currDir].keys():\n",
    "            authorFeatures[currDir][key] = mean_var(authorFeatures[currDir][key])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In[439]:\n",
    "\n",
    "def text_class(text): \n",
    "    maxProb = -float('Inf')\n",
    "    maxAuth = ''\n",
    "    vocabSize = len(VOCABULARY)\n",
    "\n",
    "    sentenceCount = text.count('.')\n",
    "    commaCount = text.count(',')\n",
    "    exclamationCount = text.count('!')\n",
    "    questionCount = text.count('?')\n",
    "    \n",
    "    tokens = tokenize(text,1)\n",
    "    prob = 0\n",
    "    for authName in authorBags:\n",
    "        n = sum(authorBags[authName].values())\n",
    "        #print(n , authName)\n",
    "        prob = 0\n",
    "        wordLength = 0\n",
    "        \n",
    "        for token in tokens:\n",
    "            wordLength += len(token)\n",
    "            smoother = 0.004\n",
    "            if token in authorBags[authName]:\n",
    "                tokenProb = (authorBags[authName][token]+smoother)/(n+smoother*vocabSize)\n",
    "            else:\n",
    "                tokenProb = smoother/(n+smoother*vocabSize)\n",
    "            prob = prob + np.log(tokenProb)\n",
    "            #print('tokenProb = ' , tokenProb)\n",
    "        \n",
    "        wordLength /= len(tokens)\n",
    "        \n",
    "        authorProb = DOCUMENT_COUNT_PER_AUTHOR[authName] / TOTAL_TRAINING_DOCUMENT_COUNT\n",
    "        #print('authorProb = ', np.log(authorProb))\n",
    "        prob += np.log(authorProb)\n",
    "        \n",
    "        prob -= 2*z_score(authorFeatures[authName]['wordCount'][0], \n",
    "                          authorFeatures[authName]['wordCount'][1], \n",
    "                          len(tokens))\n",
    "        \n",
    "        prob -= 2*z_score(authorFeatures[authName]['sentenceCount'][0], \n",
    "                           authorFeatures[authName]['sentenceCount'][1], \n",
    "                           sentenceCount)\n",
    "        \n",
    "        prob -= 2*z_score(authorFeatures[authName]['wordLength'][0], \n",
    "                           authorFeatures[authName]['wordLength'][1], \n",
    "                           wordLength)\n",
    "        \n",
    "        prob -= 2*z_score(authorFeatures[authName]['commaCount'][0], \n",
    "                           authorFeatures[authName]['commaCount'][1], \n",
    "                           commaCount/sentenceCount)\n",
    "        \n",
    "        prob -= 2*z_score(authorFeatures[authName]['exclamationCount'][0], \n",
    "                           authorFeatures[authName]['exclamationCount'][1], \n",
    "                           exclamationCount/sentenceCount)\n",
    "        \n",
    "        prob -= 2*z_score(authorFeatures[authName]['questionCount'][0], \n",
    "                           authorFeatures[authName]['questionCount'][1], \n",
    "                           questionCount/sentenceCount)\n",
    "        \n",
    "        \"\"\"prob += np.log(gaussian_pdf_value(authorFeatures[authName]['wordCount'][0], \n",
    "                          authorFeatures[authName]['wordCount'][1], \n",
    "                          len(tokens)))\n",
    "        \n",
    "        prob += np.log(gaussian_pdf_value(authorFeatures[authName]['sentenceCount'][0], \n",
    "                           authorFeatures[authName]['sentenceCount'][1], \n",
    "                           sentenceCount))\n",
    "        \n",
    "        prob += np.log(gaussian_pdf_value(authorFeatures[authName]['wordLength'][0], \n",
    "                           authorFeatures[authName]['wordLength'][1], \n",
    "                           wordLength))\n",
    "        \n",
    "        prob += np.log(gaussian_pdf_value(authorFeatures[authName]['commaCount'][0], \n",
    "                           authorFeatures[authName]['commaCount'][1], \n",
    "                           commaCount/sentenceCount))\n",
    "\n",
    "        \n",
    "        prob += np.log(gaussian_pdf_value(authorFeatures[authName]['exclamationCount'][0], \n",
    "                           authorFeatures[authName]['exclamationCount'][1], \n",
    "                           exclamationCount/sentenceCount))\n",
    "        \n",
    "        prob += np.log(gaussian_pdf_value(authorFeatures[authName]['questionCount'][0], \n",
    "                           authorFeatures[authName]['questionCount'][1], \n",
    "                           questionCount/sentenceCount))\"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"     prob -= abs(authorFeatures[authName]['wordCount'] - len(tokens))\n",
    "                prob -= abs(authorFeatures[authName]['sentenceCount'] - sentenceCount)\n",
    "                prob -= 10*abs(authorFeatures[authName]['wordLength'] - wordLength)\n",
    "                prob -= 100*abs(authorFeatures[authName]['commaCount'] - commaCount/sentenceCount)\n",
    "                prob -= 1000*abs(authorFeatures[authName]['exclamationCount'] - exclamationCount/sentenceCount)\n",
    "                prob -= 1000*abs(authorFeatures[authName]['questionCount'] - questionCount/sentenceCount)\n",
    "        \"\"\"\n",
    "        #print(wordLength)\n",
    "        #print(abs(authorFeatures[authName]['wordLength'] - wordLength))\n",
    "        if prob > maxProb:\n",
    "            maxProb = prob\n",
    "            maxAuth = authName\n",
    "        #print('Prob for auth ',authName, prob)\n",
    "    \n",
    "    #print(maxAuth)\n",
    "    return maxAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# In[440]:\n",
    "\n",
    "\"\"\"with codecs.open('./testSet/ahmetAltan/M7.txt', 'r', 'ISO-8859-9') as myfile:\n",
    "    text = myfile.read()\n",
    "    bagCounts = tokenize(text,1)\n",
    "    text_class(bagCounts)\"\"\"\n",
    "\n",
    "success = 0\n",
    "totalTrial = 0\n",
    "for dirName, subdirList, fileList in os.walk(rootDir+'/testSet'):\n",
    "    if(dirName != './testSet'):\n",
    "        currDir = dirName[10:]\n",
    "        for fname in fileList:\n",
    "            text = ''\n",
    "            with codecs.open(dirName+'/'+fname, 'r', 'ISO-8859-9') as myfile:\n",
    "                #print(dirName+'/'+fname)\n",
    "                text = myfile.read().lower()\n",
    "                auth = text_class(text)\n",
    "                totalTrial += 1\n",
    "                if auth == dirName[10:]:\n",
    "                    #print('success')\n",
    "                    success +=1\n",
    "                #else:\n",
    "                    #print('fail')\n",
    "print('Finished')\n",
    "print('Success rate :', success/ totalTrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate : 0.6703296703296703\n"
     ]
    }
   ],
   "source": [
    "# In[441]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasmetBabaoglu\n"
     ]
    }
   ],
   "source": [
    "# In[442]:\n",
    "#0.7527472527472527\n",
    "with codecs.open('./testSet/hasmetBabaoglu/8.txt', 'r', 'ISO-8859-9') as myfile:\n",
    "    text = myfile.read()\n",
    "    bagCounts = tokenize(text,1)\n",
    "    print(text_class(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.868590109271217"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score(772.6666666666666, 130.44444444444446, 146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macapple/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.439805283582\n",
      "1.61121834387\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEACAYAAACtVTGuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKyl/w9c6Y21/6v/QAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10919c8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import math\n",
    "\n",
    "a=0.1\n",
    "print(np.log(z_score(authorFeatures['abbasGuclu']['exclamationCount'][0], \n",
    "                           authorFeatures['abbasGuclu']['exclamationCount'][1], \n",
    "                           a)))\n",
    "\n",
    "\n",
    "print(z_score(authorFeatures['abbasGuclu']['wordCount'][0], \n",
    "                           authorFeatures['abbasGuclu']['wordCount'][1], \n",
    "                           500))\n",
    "\n",
    "mean = authorFeatures['abbasGuclu']['wordCount'][0]\n",
    "variance = authorFeatures['abbasGuclu']['wordCount'][1]\n",
    "sigma = math.sqrt(variance)\n",
    "x = np.linspace(-1000,1000,100)\n",
    "plt.plot(x,mlab.normpdf(x,mean,sigma))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'var' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-d64de179d453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'var' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9410835087212867e-12"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014627058398094506"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
